{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Descriptive Analysis of Fly Brain Networks\n",
        "\n",
        "This notebook performs a descriptive analysis of the Drosophila brain networks that were ingested in the previous notebook. We'll:\n",
        "\n",
        "1. Load the processed networks\n",
        "2. Clean the networks (remove self-loops, extract largest connected component)\n",
        "3. Calculate network metrics\n",
        "4. Visualize degree distributions and centrality measures\n",
        "5. Compare metrics across different brain regions\n",
        "\n",
        "The core computations are handled by the `metrics.py` and `preprocessing.py` modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src directory to path to import project modules\n",
        "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
        "\n",
        "# Import project modules\n",
        "from src import config\n",
        "from src import data_io\n",
        "from src import metrics\n",
        "from src import preprocessing\n",
        "from src import utils\n",
        "\n",
        "# Set up logging\n",
        "logger = utils.setup_logging(level=logging.INFO)\n",
        "\n",
        "# Set plotting style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Processed Networks\n",
        "\n",
        "First, let's load the networks saved in the previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define brain regions to analyze\n",
        "regions = [\"EB\", \"FB\", \"MB\"]\n",
        "\n",
        "# Dictionary to store original networks\n",
        "original_networks = {}\n",
        "\n",
        "# Load networks for each region\n",
        "for region in regions:\n",
        "    try:\n",
        "        network = data_io.load_network_from_gexf(region)\n",
        "        if network is not None:\n",
        "            original_networks[region] = network\n",
        "            print(f\"Loaded {region} network: {network.number_of_nodes()} nodes, {network.number_of_edges()} edges\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading network for region {region}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Clean Networks\n",
        "\n",
        "Let's clean the networks by removing self-loops and extracting the largest connected component."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dictionary to store cleaned networks\n",
        "cleaned_networks = {}\n",
        "\n",
        "# Clean networks for each region\n",
        "for region, network in original_networks.items():\n",
        "    try:\n",
        "        # Apply cleaning operations\n",
        "        cleaned = preprocessing.clean_graph(network)\n",
        "        cleaned_networks[region] = cleaned\n",
        "        \n",
        "        # Print summary\n",
        "        print(f\"Cleaned {region} network:\")\n",
        "        print(f\"  Original: {network.number_of_nodes()} nodes, {network.number_of_edges()} edges\")\n",
        "        print(f\"  Cleaned:  {cleaned.number_of_nodes()} nodes, {cleaned.number_of_edges()} edges\")\n",
        "        print(f\"  Reduction: {(1 - cleaned.number_of_edges()/network.number_of_edges())*100:.1f}% edges removed\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error cleaning network for region {region}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Calculate Network Metrics\n",
        "\n",
        "Now let's compute various metrics for each network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dictionary to store network metrics\n",
        "network_metrics = {}\n",
        "node_metrics = {}\n",
        "\n",
        "# Compute metrics for each cleaned network\n",
        "for region, network in cleaned_networks.items():\n",
        "    try:\n",
        "        # Compute and store metrics\n",
        "        metrics_dict, node_df = metrics.compute_all_metrics(\n",
        "            network, \n",
        "            output_dir=os.path.join(config.RESULTS_TABLES_DIR, region.lower())\n",
        "        )\n",
        "        \n",
        "        network_metrics[region] = metrics_dict\n",
        "        node_metrics[region] = node_df\n",
        "        \n",
        "        # Print summary of key metrics\n",
        "        print(f\"\\n{region} Network Metrics:\")\n",
        "        print(f\"  Nodes: {metrics_dict['num_nodes']}\")\n",
        "        print(f\"  Edges: {metrics_dict['num_edges']}\")\n",
        "        print(f\"  Density: {metrics_dict['density']:.6f}\")\n",
        "        print(f\"  Average clustering: {metrics_dict['avg_clustering']:.4f}\")\n",
        "        print(f\"  Average shortest path: {metrics_dict.get('avg_shortest_path', 'N/A')}\")\n",
        "        print(f\"  Assortativity: {metrics_dict['assortativity']:.4f}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error computing metrics for region {region}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualize Degree Distributions\n",
        "\n",
        "Let's visualize the in-degree and out-degree distributions of each network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_degree_distribution(G, region, ax=None, loglog=True):\n",
        "    \"\"\"\n",
        "    Plot the in-degree and out-degree distributions of a directed graph.\n",
        "    \"\"\"\n",
        "    if ax is None:\n",
        "        _, ax = plt.subplots(figsize=(10, 6))\n",
        "    \n",
        "    # Get degree sequences\n",
        "    in_degrees = [d for _, d in G.in_degree()]\n",
        "    out_degrees = [d for _, d in G.out_degree()]\n",
        "    \n",
        "    # Calculate degree distributions (PDF)\n",
        "    def degree_distribution(degrees):\n",
        "        # Count occurrences of each degree\n",
        "        unique_degrees = sorted(set(degrees))\n",
        "        counts = [degrees.count(d) for d in unique_degrees]\n",
        "        # Convert to probabilities\n",
        "        prob = [c / len(degrees) for c in counts]\n",
        "        return unique_degrees, prob\n",
        "    \n",
        "    in_uniq, in_prob = degree_distribution(in_degrees)\n",
        "    out_uniq, out_prob = degree_distribution(out_degrees)\n",
        "    \n",
        "    # Plot distributions\n",
        "    if loglog:\n",
        "        # Log-log plot often better for power-law distributions\n",
        "        ax.loglog(in_uniq, in_prob, 'bo-', alpha=0.7, label='In-degree')\n",
        "        ax.loglog(out_uniq, out_prob, 'ro-', alpha=0.7, label='Out-degree')\n",
        "        ax.set_xlabel('Degree (log scale)')\n",
        "        ax.set_ylabel('Probability (log scale)')\n",
        "    else:\n",
        "        ax.plot(in_uniq, in_prob, 'bo-', alpha=0.7, label='In-degree')\n",
        "        ax.plot(out_uniq, out_prob, 'ro-', alpha=0.7, label='Out-degree')\n",
        "        ax.set_xlabel('Degree')\n",
        "        ax.set_ylabel('Probability')\n",
        "    \n",
        "    ax.set_title(f'{region} Degree Distribution')\n",
        "    ax.legend()\n",
        "    \n",
        "    return ax"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}